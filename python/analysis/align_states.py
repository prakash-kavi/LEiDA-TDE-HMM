"""
State Alignment for Meditation Analysis

This script aligns HMM states across subjects by mapping them to functional 
meditation phases (Breath Focus, Mind Wandering, Meta-awareness, Redirecting).
It uses existing metrics from tde_hmm_metrics.py without computing new ones.

Outputs:
- State mapping files for each network configuration and k value
- Visualization of state fingerprints
- Consensus mappings for group-level analysis
"""

import os
import numpy as np
import pandas as pd
import pickle
import logging
import argparse
import matplotlib.pyplot as plt
from scipy.spatial.distance import pdist, squareform
from datetime import datetime

# Setup paths
ROOT_DIR = os.path.abspath(os.path.dirname(os.path.dirname(__file__)))
DATA_DIR = os.path.join(ROOT_DIR, 'data')
RESULTS_DIR = os.path.join(ROOT_DIR, 'results')
METRICS_DIR = os.path.join(RESULTS_DIR, 'metrics')
MAPPING_DIR = os.path.join(METRICS_DIR, 'state_mappings')
VIS_DIR = os.path.join(MAPPING_DIR, 'visualizations')

# Create directories if they don't exist
os.makedirs(MAPPING_DIR, exist_ok=True)
os.makedirs(VIS_DIR, exist_ok=True)

# Setup logging
logging.basicConfig(level=logging.INFO, 
                    format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Full network names for visualization labels
YEO_NETWORKS = [
    'VIS', 'SMN', 'DAN', 'VAN', 'LIM', 'FPN', 'DMN', 'SUB']

# Define networks of interest for Vipassana meditation
ATTENTION_NETWORKS = {
    'DAN': 'Dorsal Attention',       # Focus, sustained attention
    'VAN': 'Ventral Attention',      # Attention reorienting, meta-awareness
    'FPN': 'Frontoparietal',         # Executive control, regulation
    'DMN': 'Default Mode'            # Mind wandering, self-referential
}

# Define meditation phases
MEDITATION_PHASES = [
    'Breath Focus',
    'Mind Wandering',
    'Meta-awareness',
    'Redirecting'
]

def load_metrics(group, networks, k):
    """ Load metrics data generated by tde_hmm_metrics.py. """
    metrics_path = os.path.join(METRICS_DIR, f'{networks}networks', 
                               group, f'k{k}_metrics.pkl')
    
    if not os.path.exists(metrics_path):
        raise FileNotFoundError(f"Metrics file not found: {metrics_path}")
    
    with open(metrics_path, 'rb') as f:
        metrics_data = pickle.load(f)
    
    logger.info(f"Loaded metrics for {group}, {networks}-network, k={k}")
    return metrics_data

def create_state_fingerprints(metrics_data, networks, k):
    """ 
    Create multidimensional fingerprints for each state based on existing metrics.
    
    Parameters:
    -----------
    metrics_data : dict
        Metrics data from tde_hmm_metrics.py
    networks : int
        Number of networks (7 or 8)
    k : int
        Number of states
        
    Returns:
    --------
    fingerprints : dict
        Dictionary of state fingerprints for each subject
    """
    fingerprints = {}
    
    # Define network indices based on configuration
    network_names = YEO_NETWORKS[:networks]
    
    # Process each subject's metrics
    subject_metrics = metrics_data.get('subject_metrics', [])
    for subject_idx, subject_data in enumerate(subject_metrics):
        # Extract network activation patterns for each state
        state_means = subject_data.get('state_means', None)
        if state_means is None:
            logger.warning(f"Missing state means for subject {subject_idx}")
            continue
            
        # Extract temporal dynamics
        fractional_occupancy = subject_data.get('fractional_occupancy', None)
        lifetimes = subject_data.get('lifetimes', None)
        state_intervals = subject_data.get('state_intervals', None)
        
        # Extract transition patterns
        P = subject_data.get('P', None)  # Transition matrix
        
        # Extract succession patterns (if available)
        succession_probs = None
        if 'succession_results' in subject_data:
            succession_probs = subject_data['succession_results'].get('succession_probs', None)
        
        # Create fingerprints for each state
        subject_fingerprints = {}
        for state in range(k):
            # Network activations
            network_profile = {network: state_means[state, i] 
                              for i, network in enumerate(network_names)}
            
            # Temporal characteristics
            temporal_profile = {}
            if fractional_occupancy is not None and len(fractional_occupancy) > state:
                temporal_profile['fractional_occupancy'] = fractional_occupancy[state]
            
            if lifetimes is not None and len(lifetimes) > state:
                temporal_profile['mean_lifetime'] = np.mean(lifetimes[state])
                temporal_profile['max_lifetime'] = np.max(lifetimes[state])
            
            # Transition patterns
            transition_profile = {}
            if P is not None:
                transition_profile['self_transition'] = P[state, state]
                transition_profile['incoming_rates'] = P[:, state].copy()
                transition_profile['outgoing_rates'] = P[state, :].copy()
                
                # Most likely transition targets
                outgoing_probs = P[state, :]
                outgoing_probs[state] = 0  # Exclude self-transitions
                if np.sum(outgoing_probs) > 0:
                    transition_profile['max_outgoing_state'] = np.argmax(outgoing_probs)
                
                # Most likely transition sources
                incoming_probs = P[:, state].copy()
                incoming_probs[state] = 0  # Exclude self-transitions
                if np.sum(incoming_probs) > 0:
                    transition_profile['max_incoming_state'] = np.argmax(incoming_probs)
            
            # Succession patterns
            succession_profile = {}
            if succession_probs is not None:
                succession_profile['succession_outgoing'] = succession_probs[state, :].copy()
                succession_profile['succession_incoming'] = succession_probs[:, state].copy()
                
                # Most common succession targets
                outgoing_succ = succession_probs[state, :].copy()
                outgoing_succ[state] = 0  # Exclude self-successions
                if np.sum(outgoing_succ) > 0:
                    succession_profile['max_succession_target'] = np.argmax(outgoing_succ)
                
                # Most common succession sources
                incoming_succ = succession_probs[:, state].copy()
                incoming_succ[state] = 0  # Exclude self-successions
                if np.sum(incoming_succ) > 0:
                    succession_profile['max_succession_source'] = np.argmax(incoming_succ)
            
            # Combine all profiles into a fingerprint
            subject_fingerprints[state] = {
                'network_profile': network_profile,
                'temporal_profile': temporal_profile,
                'transition_profile': transition_profile,
                'succession_profile': succession_profile
            }
        
        fingerprints[subject_idx] = subject_fingerprints
    
    return fingerprints

def map_states_to_meditation_phases(fingerprints, networks):
    """
    Map each state to a meditation phase based on its fingerprint.
    
    Parameters:
    -----------
    fingerprints : dict
        Dictionary of state fingerprints
    networks : int
        Number of networks (7 or 8)
        
    Returns:
    --------
    mappings : dict
        Dictionary mapping subject states to meditation phases
    """
    mappings = {}
    
    for subject_idx, states in fingerprints.items():
        # Initialize phase scores for this subject
        phase_scores = {
            state: {phase: 0 for phase in MEDITATION_PHASES}
            for state in states
        }
        
        for state, fingerprint in states.items():
            # Extract profiles
            network_profile = fingerprint['network_profile']
            temporal_profile = fingerprint['temporal_profile']
            transition_profile = fingerprint['transition_profile']
            succession_profile = fingerprint['succession_profile']
            
            # --- Breath Focus Criteria ---
            # High SMN, Low DMN, stable (high self-transition)
            if 'SMN' in network_profile and 'DMN' in network_profile:
                if network_profile['SMN'] > 0 and network_profile['DMN'] < 0:
                    phase_scores[state]['Breath Focus'] += 2
                elif network_profile['SMN'] > network_profile['DMN']:
                    phase_scores[state]['Breath Focus'] += 1
            
            # Temporal stability
            if 'mean_lifetime' in temporal_profile:
                if temporal_profile.get('mean_lifetime', 0) > 10:  # Longer duration
                    phase_scores[state]['Breath Focus'] += 1
            
            if 'fractional_occupancy' in temporal_profile:
                if temporal_profile.get('fractional_occupancy', 0) > 0.3:  # High prevalence
                    phase_scores[state]['Breath Focus'] += 1
            
            if 'self_transition' in transition_profile:
                if transition_profile.get('self_transition', 0) > 0.7:  # Stable state
                    phase_scores[state]['Breath Focus'] += 1
            
            # --- Mind Wandering Criteria ---
            # High DMN, moderate stability
            if 'DMN' in network_profile:
                if network_profile['DMN'] > 0.5:
                    phase_scores[state]['Mind Wandering'] += 2
                elif network_profile['DMN'] > 0:
                    phase_scores[state]['Mind Wandering'] += 1
            
            # Executive control is lower
            if 'FPN' in network_profile and network_profile['FPN'] < 0:
                phase_scores[state]['Mind Wandering'] += 1
            
            # Moderate temporal stability
            if 'mean_lifetime' in temporal_profile:
                if 5 < temporal_profile.get('mean_lifetime', 0) < 15:
                    phase_scores[state]['Mind Wandering'] += 1
            
            # --- Meta-awareness Criteria ---
            # High attention networks (VAN in 8-network, DAN in both)
            if networks == 8 and 'VAN' in network_profile and network_profile['VAN'] > 0:
                phase_scores[state]['Meta-awareness'] += 2
            elif 'DAN' in network_profile and network_profile['DAN'] > 0:
                phase_scores[state]['Meta-awareness'] += 1
            
            # Often follows Mind Wandering in succession
            if 'max_succession_source' in succession_profile:
                # If most common source has high DMN, this is likely meta-awareness
                source_state = succession_profile['max_succession_source']
                if source_state in fingerprints[subject_idx]:
                    source_network = fingerprints[subject_idx][source_state]['network_profile']
                    if 'DMN' in source_network and source_network['DMN'] > 0:
                        phase_scores[state]['Meta-awareness'] += 2
            
            # --- Redirecting Criteria ---
            # High FPN (executive control), declining DMN
            if 'FPN' in network_profile and network_profile['FPN'] > 0:
                phase_scores[state]['Redirecting'] += 1
                if 'DMN' in network_profile and network_profile['DMN'] < 0:
                    phase_scores[state]['Redirecting'] += 1
            
            # Brief duration (transient state)
            if 'mean_lifetime' in temporal_profile:
                if temporal_profile.get('mean_lifetime', float('inf')) < 5:
                    phase_scores[state]['Redirecting'] += 1
            
            # Low self-transition (unstable state)
            if 'self_transition' in transition_profile:
                if transition_profile.get('self_transition', 1) < 0.5:
                    phase_scores[state]['Redirecting'] += 1
            
            # Often transitions to Breath Focus
            if 'max_succession_target' in succession_profile:
                target_state = succession_profile['max_succession_target']
                if target_state in fingerprints[subject_idx]:
                    target_network = fingerprints[subject_idx][target_state]['network_profile']
                    if 'SMN' in target_network and target_network['SMN'] > 0:
                        phase_scores[state]['Redirecting'] += 2
        
        # Assign each state to its highest-scoring phase
        subject_mapping = {}
        for state in states:
            best_phase = max(phase_scores[state].items(), key=lambda x: x[1])
            if best_phase[1] > 0:  # Only map if score is positive
                subject_mapping[state] = best_phase[0]
            else:
                subject_mapping[state] = 'Unknown'
        
        mappings[subject_idx] = subject_mapping
    
    return mappings

def create_consensus_mapping(mappings, k):
    """
    Create a consensus mapping across subjects.
    
    Parameters:
    -----------
    mappings : dict
        Dictionary of subject mappings
    k : int
        Number of states
        
    Returns:
    --------
    consensus : dict
        Consensus mapping of states to phases
    """
    # Initialize counts for each phase-state combination
    phase_state_counts = {phase: {state: 0 for state in range(k)} 
                         for phase in MEDITATION_PHASES}
    
    # Count how often each state is mapped to each phase
    for subject_idx, subject_mapping in mappings.items():
        for state, phase in subject_mapping.items():
            if phase in MEDITATION_PHASES:
                phase_state_counts[phase][state] += 1
    
    # Find the most commonly assigned state for each phase
    consensus = {}
    for phase, state_counts in phase_state_counts.items():
        if any(state_counts.values()):
            best_state = max(state_counts.items(), key=lambda x: x[1])
            if best_state[1] > 0:  # Only include if at least one subject maps to this
                consensus[phase] = best_state[0]
    
    return consensus

def visualize_state_fingerprints(fingerprints, mappings, group, networks, k):
    """
    Create visualizations of state fingerprints.
    
    Parameters:
    -----------
    fingerprints : dict
        Dictionary of state fingerprints
    mappings : dict
        Dictionary of state mappings
    group : str
        'meditators' or 'controls'
    networks : int
        Number of networks
    k : int
        Number of states
    """
    # Create a directory for this configuration
    config_dir = os.path.join(VIS_DIR, f'{networks}networks_k{k}')
    os.makedirs(config_dir, exist_ok=True)
    
    # Get network names
    network_names = YEO_NETWORKS[:networks]
    
    # Create heatmap of network activations across states and subjects
    plt.figure(figsize=(12, 8))
    
    # Prepare data for heatmap
    subjects = list(fingerprints.keys())
    states = list(range(k))
    
    # For each state
    for state in states:
        plt.figure(figsize=(10, 6))
        
        # Extract network profiles for this state across subjects
        network_data = np.zeros((len(subjects), len(network_names)))
        for i, subject in enumerate(subjects):
            if state in fingerprints[subject]:
                for j, network in enumerate(network_names):
                    network_data[i, j] = fingerprints[subject][state]['network_profile'].get(network, 0)
        
        # Create heatmap
        plt.imshow(network_data, aspect='auto', cmap='RdBu_r', vmin=-1, vmax=1)
        plt.colorbar(label='Z-score activation')
        
        # Add labels
        plt.xlabel('Networks')
        plt.ylabel('Subjects')
        plt.title(f"{group} - State {state} Network Activation Profiles")
        
        # Add network labels
        plt.xticks(range(len(network_names)), network_names, rotation=45)
        
        # Add phase labels from mapping
        phase_labels = []
        for subject in subjects:
            if subject in mappings and state in mappings[subject]:
                phase_labels.append(mappings[subject][state])
            else:
                phase_labels.append('Unknown')
        
        # Add a second y-axis for phase labels
        ax2 = plt.twinx()
        ax2.set_yticks(range(len(subjects)))
        ax2.set_yticklabels(phase_labels)
        ax2.set_ylabel('Mapped Phase')
        
        # Save figure
        plt.tight_layout()
        plt.savefig(os.path.join(config_dir, f'{group}_state{state}_network_profile.png'))
        plt.close()
    
    # Create summary visualization of mapping consistency
    plt.figure(figsize=(8, 6))
    
    # Calculate how consistently each state is mapped to each phase
    consistency_matrix = np.zeros((k, len(MEDITATION_PHASES)))
    for subject, mapping in mappings.items():
        for state, phase in mapping.items():
            if phase in MEDITATION_PHASES:
                phase_idx = MEDITATION_PHASES.index(phase)
                consistency_matrix[state, phase_idx] += 1
    
    # Normalize by number of subjects
    consistency_matrix = consistency_matrix / len(mappings)
    
    # Create heatmap
    plt.imshow(consistency_matrix, aspect='auto', cmap='viridis', vmin=0, vmax=1)
    plt.colorbar(label='Proportion of subjects')
    
    # Add labels
    plt.xlabel('Meditation Phase')
    plt.ylabel('State')
    plt.title(f"{group} - State to Phase Mapping Consistency")
    
    # Add phase labels
    plt.xticks(range(len(MEDITATION_PHASES)), MEDITATION_PHASES, rotation=45)
    plt.yticks(range(k), [f"S{s}" for s in range(k)])
    
    # Save figure
    plt.tight_layout()
    plt.savefig(os.path.join(config_dir, f'{group}_mapping_consistency.png'))
    plt.close()

def save_state_mapping(mappings, consensus, group, networks, k):
    """Save state mappings to CSV for use by other analyses."""
    # Create mapping dataframe
    mapping_rows = []
    
    # Add subject-specific mappings
    for subject_idx, subject_mapping in mappings.items():
        for state, phase in subject_mapping.items():
            mapping_rows.append({
                'group': group,
                'networks': networks,
                'k': k,
                'subject_idx': subject_idx,
                'state_idx': state,
                'meditation_phase': phase,
                'mapping_type': 'subject'
            })
    
    # Add consensus mapping
    for phase, state in consensus.items():
        mapping_rows.append({
            'group': group,
            'networks': networks,
            'k': k,
            'subject_idx': -1,  # -1 indicates group-level
            'state_idx': state,
            'meditation_phase': phase,
            'mapping_type': 'consensus'
        })
    
    # Log if mapping_rows is empty
    if not mapping_rows:
        logger.warning(f"No mappings found for {group}, {networks}networks_k{k}")
        # Add a dummy mapping to prevent empty files
        mapping_rows.append({
            'group': group,
            'networks': networks,
            'k': k,
            'subject_idx': -1,
            'state_idx': -1,
            'meditation_phase': 'No mappings found',
            'mapping_type': 'error'
        })
    else:
        logger.info(f"Found {len(mapping_rows)} mappings for {group}, {networks}networks_k{k}")
    
    # Create dataframe
    mapping_df = pd.DataFrame(mapping_rows)
    
    # Save to CSV with explicit encoding to avoid issues
    mapping_path = os.path.join(MAPPING_DIR, f'{group}_{networks}networks_k{k}_mapping.csv')
    mapping_df.to_csv(mapping_path, index=False, encoding='utf-8')
    
    # Verify file was written correctly
    if os.path.exists(mapping_path) and os.path.getsize(mapping_path) > 0:
        logger.info(f"Successfully saved state mapping to {mapping_path} (size: {os.path.getsize(mapping_path)} bytes)")
    else:
        logger.error(f"Failed to save state mapping properly to {mapping_path}")
    
    return mapping_path

def debug_mapping_files(group, networks, k):
    """Debug helper to check why mapping files are empty."""
    mapping_path = os.path.join(MAPPING_DIR, f'{group}_{networks}networks_k{k}_mapping.csv')
    
    # Check file content
    if os.path.exists(mapping_path):
        file_size = os.path.getsize(mapping_path)
        logger.info(f"Debug: {mapping_path} exists with size {file_size} bytes")
        
        try:
            with open(mapping_path, 'r') as f:
                content = f.read()
                logger.info(f"File content first 100 chars: {content[:100]}")
                
            # Try reading with pandas
            try:
                df = pd.read_csv(mapping_path)
                logger.info(f"DataFrame shape: {df.shape}, columns: {df.columns.tolist()}")
            except Exception as e:
                logger.error(f"Error reading CSV with pandas: {e}")
        except Exception as e:
            logger.error(f"Error reading file: {e}")
    else:
        logger.error(f"Debug: File {mapping_path} does not exist")

def combine_group_mappings(k_values=[4, 5], networks_list=[7, 8]):
    """Combine mappings from both groups to create unified mapping files."""
    for networks in networks_list:
        for k in k_values:
            # Load both group mappings
            meditator_path = os.path.join(MAPPING_DIR, f'meditators_{networks}networks_k{k}_mapping.csv')
            control_path = os.path.join(MAPPING_DIR, f'controls_{networks}networks_k{k}_mapping.csv')
            
            if not os.path.exists(meditator_path) or not os.path.exists(control_path):
                logger.warning(f"Skipping combined mapping for {networks}networks_k{k}: files not found")
                continue
            
            # Check file validity
            try:
                if os.path.getsize(meditator_path) == 0 or os.path.getsize(control_path) == 0:
                    logger.warning(f"Skipping combined mapping for {networks}networks_k{k}: empty mapping file(s)")
                    continue
                
                # Load mappings
                meditator_df = pd.read_csv(meditator_path)
                control_df = pd.read_csv(control_path)
                
                # Verify content
                if meditator_df.empty or control_df.empty:
                    logger.warning(f"Skipping combined mapping for {networks}networks_k{k}: empty DataFrame(s)")
                    continue
                
                # Combine dataframes
                combined_df = pd.concat([meditator_df, control_df], ignore_index=True)
                
                # Save combined mapping
                combined_path = os.path.join(MAPPING_DIR, f'state_mapping_{networks}networks_k{k}.csv')
                combined_df.to_csv(combined_path, index=False)
                logger.info(f"Saved combined mapping to {combined_path}")
                
            except Exception as e:
                logger.error(f"Error creating combined mapping for {networks}networks_k{k}: {e}")

def run_state_alignment(k_values=[4, 5], networks_list=[7, 8]):
    """Run the state alignment procedure with in-memory data combination."""
    for networks in networks_list:
        logger.info(f"Processing {networks}-network configurations")
        
        for k in k_values:
            logger.info(f"Processing k={k} models")
            
            # Store mappings in memory
            group_mappings = {}
            group_consensus = {}
            
            for group in ['meditators', 'controls']:
                logger.info(f"Aligning {group} states")
                
                try:
                    # Load metrics data
                    metrics_data = load_metrics(group, networks, k)
                    
                    # Create state fingerprints
                    fingerprints = create_state_fingerprints(metrics_data, networks, k)
                    
                    # Map states to meditation phases
                    mappings = map_states_to_meditation_phases(fingerprints, networks)
                    
                    # Create consensus mapping
                    consensus = create_consensus_mapping(mappings, k)
                    
                    # Store in memory
                    group_mappings[group] = mappings
                    group_consensus[group] = consensus
                    
                    # Visualize state fingerprints
                    visualize_state_fingerprints(fingerprints, mappings, group, networks, k)
                    
                    # Save individual group mapping
                    save_state_mapping(mappings, consensus, group, networks, k)
                    
                except Exception as e:
                    logger.error(f"Error aligning {group} states for {networks}networks_k{k}: {e}")
                    import traceback
                    traceback.print_exc()
            
            # After processing both groups, combine their mappings in memory
            try:
                # Create combined mapping dataframe directly
                combined_rows = []
                
                # Add meditator mappings
                if 'meditators' in group_mappings:
                    for subject_idx, subject_mapping in group_mappings['meditators'].items():
                        for state, phase in subject_mapping.items():
                            combined_rows.append({
                                'group': 'meditators',
                                'networks': networks,
                                'k': k,
                                'subject_idx': subject_idx,
                                'state_idx': state,
                                'meditation_phase': phase,
                                'mapping_type': 'subject'
                            })
                
                # Add control mappings
                if 'controls' in group_mappings:
                    for subject_idx, subject_mapping in group_mappings['controls'].items():
                        for state, phase in subject_mapping.items():
                            combined_rows.append({
                                'group': 'controls',
                                'networks': networks,
                                'k': k,
                                'subject_idx': subject_idx,
                                'state_idx': state,
                                'meditation_phase': phase,
                                'mapping_type': 'subject'
                            })
                
                # Add consensus mappings for both groups
                for group, consensus in group_consensus.items():
                    for phase, state in consensus.items():
                        combined_rows.append({
                            'group': group,
                            'networks': networks,
                            'k': k,
                            'subject_idx': -1,
                            'state_idx': state,
                            'meditation_phase': phase,
                            'mapping_type': 'consensus'
                        })
                
                # Create and save combined dataframe
                if combined_rows:
                    combined_df = pd.DataFrame(combined_rows)
                    combined_path = os.path.join(MAPPING_DIR, f'state_mapping_{networks}networks_k{k}.csv')
                    combined_df.to_csv(combined_path, index=False)
                    logger.info(f"Saved combined mapping to {combined_path}")
                else:
                    logger.warning(f"No mappings to combine for {networks}networks_k{k}")
                    
            except Exception as e:
                logger.error(f"Error creating combined mapping for {networks}networks_k{k}: {e}")
                import traceback
                traceback.print_exc()

def main():
    """Main function for state alignment."""
    logger.info("=== Starting State Alignment ===")
    
    # Configure argument parser
    parser = argparse.ArgumentParser(description='State Alignment for Meditation Analysis')
    parser.add_argument('--networks', type=int, nargs='+', default=[7, 8],
                        help='Network configurations to analyze (default: 7 8)')
    parser.add_argument('--k-values', type=int, nargs='+', default=[4, 5],
                        help='K values to analyze (default: 4 5)')
    args = parser.parse_args()
    
    logger.info(f"Aligning states for networks: {args.networks}, k values: {args.k_values}")
    
    try:
        # Run state alignment
        run_state_alignment(k_values=args.k_values, networks_list=args.networks)
        logger.info(f"State alignment complete. Results saved to {MAPPING_DIR}")
        
    except Exception as e:
        logger.error(f"Error in state alignment: {str(e)}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()